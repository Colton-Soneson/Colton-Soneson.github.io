<!doctype html>

<html>
  <head>
    <meta charset="utf-8">
    <title>WebGPU Life</title>
  </head>
  <body>
    <canvas width="512" height="512"></canvas>
    <script type="module">
		const canvas = document.querySelector("canvas");

		if (!navigator.gpu) 
		{
			throw new Error("WebGPU not supported on this browser.");
		}
		
		//adapter options can be passed in for specific hardware feature requests
		const adapter = await navigator.gpu.requestAdapter();
		if (!adapter) 
		{
			throw new Error("No appropriate GPUAdapter found.");
		}
		
		//device options can be passed in for specific hardware feature requests
		const device = await adapter.requestDevice();
		
		
		const context = canvas.getContext("webgpu");
		const canvasFormat = navigator.gpu.getPreferredCanvasFormat();	//webgpu's suggestion for canvas type
		context.configure({
			device: device,
			format: canvasFormat,	//format is the texture format that should be used
		});
		/*
		//interface to record GPU Commands, necessary for basically everything
		const encoder = device.createCommandEncoder();
		
		//begin render pass
		//	give texture view property of colorAttachment
		const pass = encoder.beginRenderPass({
			colorAttachments: [{
				view: context.getCurrentTexture().createView(),	//getCurrentTexture is getting ENTIRE canvas in this case
				loadOp: "clear",		//clear texture when renderpass starts
				storeOp: "store",		//once rp is finished, store results into the texture
			}]	
		});
		
		//end to the render pass "pass"
		pass.end();
		
		//command buffer for recording commands, assigned by finish function on command encoder
		//const commandBuffer = encoder.finish();
		
		//submit commands in queue, submit function can take an array of command buffers if needed
		//device.queue.submit([commandBuffer]);
		
		//combining the two into one, and its done
		device.queue.submit([encoder.finish()]);
		
		//--------------CANVAS COLOR-----------------
		//new render pass, so different from the first
		const encoder2 = device.createCommandEncoder();
		const pass2 = encoder2.beginRenderPass({
		colorAttachments: [{
			view: context.getCurrentTexture().createView(),
			loadOp: "clear",
			clearValue: { r: 0, g: 0, b: 0.4, a: 1 }, // New line
			storeOp: "store",
			}],
		});
		
		pass2.end();
		
		device.queue.submit([encoder2.finish()]);
		//--------------------------------------------
		*/
		const vertices = new Float32Array([
		//   X,    Y,
			-0.8, -0.8, // Triangle 1 (Blue)
			0.8, -0.8,
			0.8,  0.8,
			
			-0.8, -0.8, // Triangle 2 (Red)
			0.8,  0.8,
			-0.8,  0.8,
		]);
		
		//function should return GPUShaderModule object if compiled with valid results, code itself is WGSL
		const cellShaderModule = device.createShaderModule({
		label: "Cell shader",
		code: `
			@vertex
			fn vertexMain(@location(0) pos: vec2f) -> 	// location and type to match whats described in vertexBufferLayout below
														//		the 0 in location is for shaderLocation attribute and vec2f = float32x2
				@builtin(position) vec4f {	// -> is for what the function returns, value returned is assigned with @builtin 
				return vec4f(pos, 0, 1); // (X, Y, Z, W) W is always 1 for 4x4 mat math
			}
			
			@fragment
			fn fragmentMain() -> @location(0) vec4f {	//return value to indicate which coloarAttachnment from beginRenderPass is written to
														//	Just one attachment of color means location is 0
				return vec4f(1,0,0,1);
			}
		`
		});
		
		
		
		//GPU Side memory management done through GPUBuffer objects
		//	since its so simple, theres no need to do index buffer, but the process I imagine is similar
		const vertexBuffer = device.createBuffer({
			label: "Cell vertices",		//just helps to identify object, can be anything you type
			size: vertices.byteLength,	//for 12 float vertices thats 48 bytes, cant be resized after creation
			usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,	//its use is for vertex data, and that you want to copy data into it
		});
		
		//copy vertex data to buffer
		device.queue.writeBuffer(vertexBuffer, /*bufferOffset=*/0, vertices);
		
		//now tell WebGPU what the hell to do with the info
		const vertexBufferLayout = {
		arrayStride: 8,			//number of bytes gpu needs to skip forward to get to the next vertex (with two vertices per vertex, thats 
								//	two 32 bit floats, so 2 x 4(bytes) = 8 bytes
		attributes: [{			//stuff like color, normal direction, etc
			format: "float32x2",//cant be anything, there is a list of GPUVertexFormat types in this case, its specific to pass in
			offset: 0,			//how many bytes into the vertex this attribute starts, use if you have more than one attribute
			shaderLocation: 0, // Position, see vertex shader, can be 0 - 15 and is unique to each attribute
			}],
		};
		
		
		//finally creating render pipeline
		const cellPipeline = device.createRenderPipeline({
			label: "Cell pipeline",
			layout: "auto",						// types of inputs other than vertex buffers needed can be passed
			vertex: {							// vertex stage details
				module: cellShaderModule,		// 
				entryPoint: "vertexMain",		// our name of function, as you can have multiple vertex/fragment functions in one shader module
				buffers: [vertexBufferLayout]	// GPUVertexBufferLayout that describe data packed into vertex buffers used
			},
			fragment: {							// fragment stage details
				module: cellShaderModule,		
				entryPoint: "fragmentMain",
				targets: [{						// array of dictionaries giving details (like the texture "format") of color attachments pipeline outputs to
				format: canvasFormat			// we used textures from canvas context, and value saved from canvasFormat for format, so pass the same here
				}]
			}
		});
		
		const encoder3 = device.createCommandEncoder();
		const pass3 = encoder3.beginRenderPass({
		colorAttachments: [{
			view: context.getCurrentTexture().createView(),
			loadOp: "clear",
			clearValue: { r: 0, g: 0.2, b: 0, a: 1 },
			storeOp: "store",
			}],
		});
		
		pass3.setPipeline(cellPipeline);			// shaders used, layout of vertex data, other relevant state data
		pass3.setVertexBuffer(0, vertexBuffer);		// bugger containing vertices for square, with 0th element in cellPipeline's vertex.buffers definition 
		pass3.draw(vertices.length / 2);			// passed in is number of vertices to render, 12 floats / 2 coords per float = 6 vertices
		
		pass3.end();
		
		device.queue.submit([encoder3.finish()]);
		
    </script>
  </body>
</html>